#!/usr/bin/env python3
import tensorflow as tf
import numpy as np
import glob
import subprocess
import argparse
import os 
import sys 
import json
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense, Flatten, Dropout
from tensorflow.keras.layers import Conv2D, Input
from tensorflow.keras.layers import MaxPooling2D, ZeroPadding2D
from tensorflow.keras.models import Model
#from keras_efficientnets import EfficientNetB0
from efficientnet import EfficientNetB0
import time
import datetime

# ======= Usage =========
# For PS node,     ./s-bench --ps='node0_ip_addr:5001' --worker='node1_ip_addr:5002' --strategy=parameter_server --task='ps:0'
# For worker node, ./s-bench --ps='node0_ip_addr:5001' --worker='node1_ip_addr:5002' --strategy=parameter_server --task='worker:0'

# ======= MultiWorkerMirror Usage ======
# ./s-bench --worker='node0_ip_addr:5001,node1_ip_addr:5001' --strategy=multiworkermirror --task='worker:0' 

class LoggerHook(tf.estimator.SessionRunHook):
    # Logs loss and step time
    def begin(self):
        self._step = -1
        self._start_time = time.time()
        
    def before_run(self, run_context):
        self._step += 1
        return tf.train.SessionRunArgs(None)
    
    def after_run(self, run_context, run_values):
        log_frequency = 10
        if self._step % 10 == 0:
            current_time = time.time()
            duration = current_time - self._start_time
            self._start_time = current_time
            
            loss_value = run_values.results
                                
            examples_per_sec = log_frequency * args.batch_size / duration

            sec_per_batch = float(duration / log_frequency)
            losses = run_context.session.graph.get_collection("losses")            
            format_str = ('%s: step %d, (%.1f examples/sec; %.3f '
                          'sec/batch), losses:%s')

            print (format_str % (datetime.datetime.now(), self._step, 
                                   examples_per_sec, sec_per_batch, run_context.session.run(losses)))

def build_trivial():
    # Use functional API to implement a trivial convolution neural network
    inputs = Input(shape=(227, 227, 3))
    x = Conv2D(64, (3, 3))(inputs)
    y = Conv2D(64, (3, 3))(x)
    y = ZeroPadding2D((1,1))(y)
    z = tf.keras.layers.add([x,y])
    z = MaxPooling2D((6, 6),256)(z)
    out = Flatten()(z)
    #TODO: check why usig dense can cause RuntimeError: Variable creator scope nesting error
    #out = Dense(1000, activation='softmax')(out)
    model = Model(inputs, out)    
    return model

def build_alexnet():
    print('Manually building AlexNet...')
    model = Sequential()
    model.add(Conv2D(96,(11,11),strides=(4,4),input_shape=(227,227,3),padding='valid',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
    model.add(Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
    model.add(Flatten())
    model.add(Dense(4096,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4096,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1000,activation='softmax'))
    print('AlexNet Model buidling is done.')
    return model


def build_efficientnet():
    model = EfficientNetB0(weights='imagenet')
    model = EfficientNetB0(classes=1000, include_top=True, weights='imagenet')
    return model

def imgs_input_fn(filenames, labels, batch_size, input_name, img_shape, img_size):
    def _parse_function(filename, label, input_name, img_shape, img_size):
        image_string = tf.io.read_file(filename)
        image = tf.io.decode_image(image_string, channels=3)
        image.set_shape([None, None, None])
        image = tf.image.resize(image, img_size)
        image.set_shape(img_shape)
        image = tf.reverse(image, axis=[2]) # 'RGB'->'BGR'
        d = dict(zip([input_name], [image])), label
        return d 
    if labels is None:
        labels = [1]*len(filenames)
    labels=np.array(labels)
    if len(labels.shape) == 1:
        labels = np.expand_dims(labels, axis=1)
    filenames = tf.constant(filenames)
    labels = tf.constant(labels)
    labels = tf.cast(labels, tf.float32)
    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
    dataset = dataset.map(lambda filename, label : _parse_function(filename, label, input_name, img_shape, img_size))
    dataset = dataset.shuffle(buffer_size=256)
    dataset = dataset.repeat(args.num_batches)  # Repeats dataset this # times
    dataset = dataset.batch(batch_size)  # Batch size to use
    # if using distribute.Strategy(), must use "return dataset" instead of "return batch_features, batch_lables" 
    return dataset


if __name__ == '__main__':
    #tf.compat.v1.logging.set_verbosity(10)
    tf_version = tuple(map(int, tf.__version__.split('.')))
    if tf_version < (1,14,0):
        print('tensorflow-gpu > 1.14.0 is required!')
        sys.exit(-1)
    default_raw_data_dir = os.environ['HOME']+'/mini-imagenet/raw-data/train/n01440764/'
    default_ckpt_dir = 'mycheckpoint'
    parser = argparse.ArgumentParser()
    parser.add_argument('--model', help='imagenet model name.', default='resnet50')
    parser.add_argument('--strategy', help='strategy of variable updating', default='mirrored')
    parser.add_argument('--num_gpus', help='number of GPUs used', default=1, type=int)
    parser.add_argument('--raw_data_dir', help='path to directory containing training dataset', default=default_raw_data_dir)
    parser.add_argument('--logdir', help='path to directory containing logs', default='sbench_log')
    parser.add_argument('--ckpt_dir', help='path to checkpoint directory', default=default_ckpt_dir)
    parser.add_argument('--num_batches', help='number of batches (a.k.a. steps or iterations', type=int, default=20)
    parser.add_argument('--batch_size', help='batch size per device (e.g. 32,64)', type=int, default=64)
    parser.add_argument('--worker', help='e.g. "host1:2222,host2:2222"')
    parser.add_argument('--ps', help='e.g. "host1:2220,host2:2220"')
    parser.add_argument('--task', help='e.g. "worker:0"')
    parser.add_argument('--summary-only', action='store_true')
    parser.add_argument('--clean', action='store_true')

    args = parser.parse_args()
    
    model = None

    if args.clean:
        subprocess.call('rm -rf /tmp/tmp*',shell=True)
        subprocess.call('du -sh /tmp/*',shell=True)
        sys.exit(0)

    if not os.path.isdir(args.raw_data_dir):
        print('Cannot find %s' % args.raw_data_dir)
        sys.exit(-1)

    print("logdir = %s" % args.logdir)
    if os.path.isdir(args.logdir):
        subprocess.call('rm -rf %s/*' % args.logdir, shell=True) 
    else:
        subprocess.call('mkdir -p %s' % args.logdir, shell=True) 

    if args.model is not None:
        print('Training model: ', args.model)
        if args.model == 'resnet50':
            model = tf.keras.applications.ResNet50(weights=None)
        elif args.model == 'alexnet':
            model = build_alexnet() 
        elif args.model == 'inception_v3':
            model = tf.keras.applications.inception_v3.InceptionV3(weights=None)
        elif args.model == 'vgg16':
            model = tf.keras.applications.vgg16.VGG16(weights=None) 
        elif args.model == 'inception_resnet_v2':
            model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(weights=None)
        elif args.model == 'mobilenet':
            model = tf.keras.applications.mobilenet.MobileNet(weights=None)
        elif args.model == 'mobilenet_v2':
            model = tf.keras.applications.mobilenet_v2.MobileNetV2(weights=None)
        elif args.model == 'densenet':
            model = tf.keras.applications.densenet.DenseNet201(weights=None)
        elif args.model == 'nasnet':
            model = tf.keras.applications.nasnet.NASNetLarge(weights=None)
        # TODO:train with efficientnet.
        elif args.model == 'efficientnet':
            model = build_efficientnet() 
        elif args.model == 'trivial':
            model = build_trivial()
        else:
            print('model ' + args.model + ' is not defined.') 
            sys.exit(-1)


    #subprocess.call('rm -rf %s' % args.ckpt_dir, shell=True)

    input_name = model.input_names[0]
    img_shape = [227, 227, 3]
    img_size = [227, 227]

    if args.summary_only:
        print(model.summary())
        print('imagenet image shape:')
        print(img_shape)
        print('imagenet image size:')
        print(img_size)
        sys.exit(0)
 
    filenames = glob.glob(args.raw_data_dir+"*.JPEG")
    
    # if using distribute.Strategy(), only tensorflow native optimizer is allowed currently.
    if args.strategy == 'mirrored':
        distribution = tf.distribute.MirroredStrategy()
    elif args.strategy == 'hc':
        distribution = tf.distribute.HierarchicalCopyAllReduce()
    elif args.strategy == 'parameter_server':
        tf_config = { "cluster": { "worker": args.worker.split(',')},
                      "task": { "type": args.task.split(':')[0], 
                                "index": args.task.split(':')[1]}
                    }
        if args.ps != None:
            tf_config['cluster']['ps'] = args.ps.split(',')
        print(json.dumps(tf_config))
        os.environ['TF_CONFIG'] = json.dumps(tf_config)
        if args.task.split(':')[0] == 'ps':
            os.environ['CUDA_VISIBLE_DEVICES'] = ''
        distribution = tf.distribute.experimental.ParameterServerStrategy()
    elif args.strategy == 'collective':
        distribution = tf.distribute.experimental.CollectiveAllReduceStrategy(num_gpus_per_worker=2)
    elif args.strategy == 'one_device':
        distribution = tf.distribute.OneDeviceStrategy(device='cpu')
    elif args.strategy == 'multiworkermirror':
        tf_config = { "cluster": { "worker": args.worker.split(',')},
                      "task": { "type": args.task.split(':')[0],
                                "index": args.task.split(':')[1]}
                    }
        os.environ['TF_CONFIG'] = json.dumps(tf_config)
        distribution = tf.distribute.experimental.MultiWorkerMirroredStrategy()   
    else:
        print('Not supported strategy.')
        sys.exit(-1)

    
    model.compile(optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.0001),
                          loss='categorical_crossentropy',
                          metric='accuracy')
    # Create a callalble object: fn_image_preprocess
    fn_image_preprocess = lambda : imgs_input_fn(filenames, None, args.batch_size, input_name, img_shape, img_size)
    

    if args.strategy in ['mirrored', 'one_device', 'hc']:
        config = tf.estimator.RunConfig( train_distribute = distribution)
        est = tf.keras.estimator.model_to_estimator( keras_model = model,
                                                       config = config)
        est.train( input_fn = fn_image_preprocess , steps = args.num_batches, hooks=[LoggerHook()])
    elif args.strategy == 'parameter_server':
        print('Training with Parameter Server') 
        config = tf.estimator.RunConfig( train_distribute = distribution)
        est = tf.keras.estimator.model_to_estimator( keras_model = model,
                                                       config = config)
        train_spec = tf.estimator.TrainSpec(input_fn=fn_image_preprocess, max_steps = args.num_batches, hooks=[LoggerHook()] )
        eval_spec = tf.estimator.EvalSpec(input_fn=fn_image_preprocess, steps = 1)
        tf.estimator.train_and_evaluate(est, train_spec, eval_spec) 
        print("Train and evaluate are done.")
    elif args.strategy == 'multiworkermirror':
        print('Training with MultiWorkerMirror')
        config = tf.estimator.RunConfig( train_distribute = distribution)
        est = tf.keras.estimator.model_to_estimator( keras_model = model,
                                                     config = config)
        train_spec = tf.estimator.TrainSpec(input_fn=fn_image_preprocess, max_steps = args.num_batches, hooks=[LoggerHook()] )
        eval_spec = tf.estimator.EvalSpec(input_fn=fn_image_preprocess, steps = 1)
        tf.estimator.train_and_evaluate(est, train_spec, eval_spec)  
    else:
        print('Not supported strategy.')
        sys.exit(-1)

    subprocess.call('rm -rf /tmp/tmp*',shell=True)
    subprocess.call('rm -rf %s' % args.ckpt_dir, shell=True)
    print('S-Bench is done.')

