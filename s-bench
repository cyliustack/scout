#!/usr/bin/env python3
import tensorflow as tf
from keras.applications import Xception
from keras.applications import ResNet50
from keras.utils import multi_gpu_model
import keras
import keras.backend as K
import numpy as np
import glob
import subprocess
import argparse
import os 
import sys 

def imgs_input_fn(filenames, labels=None, perform_shuffle=False, repeat_count=25, batch_size=64):
    def _parse_function(filename, label):
        image_string = tf.read_file(filename)
        image = tf.image.decode_image(image_string, channels=3)
        image.set_shape([None, None, None])
        image = tf.image.resize_images(image, [224, 224])
        image.set_shape([224, 224, 3])
        image = tf.reverse(image, axis=[2]) # 'RGB'->'BGR'
        d = dict(zip(["input_2"], [image])), label
        return d 
    if labels is None:
        labels = [0]*len(filenames)
    labels=np.array(labels)
    if len(labels.shape) == 1:
        labels = np.expand_dims(labels, axis=1)
    filenames = tf.constant(filenames)
    labels = tf.constant(labels)
    labels = tf.cast(labels, tf.float32)
    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
    dataset = dataset.map(_parse_function)
    if perform_shuffle:
        # Randomizes input using a window of 256 elements (read into memory)
        dataset = dataset.shuffle(buffer_size=256)
    dataset = dataset.repeat(repeat_count)  # Repeats dataset this # times
    dataset = dataset.batch(batch_size)  # Batch size to use
    iterator = dataset.make_one_shot_iterator()
    batch_features, batch_labels = iterator.get_next()
    # if using distribute.Strategy(), must use "return dataset" instead of "return batch_features, batch_lables" 
    return dataset


if __name__ == '__main__':
    default_data_dir = os.getenv("HOME")+'/mini-imagenet'
    default_ckpt_dir = 'mycheckpoint'
    parser = argparse.ArgumentParser()
    parser.add_argument('--model', help='imagenet model name.', default='resnet50')
    parser.add_argument('--strategy', help='strategy of variable updating', default='parameter_server')
    parser.add_argument('--num_gpus', help='number of GPUs used', default=1, type=int)
    parser.add_argument('--data_dir', help='path to directory containing training dataset', default=default_data_dir)
    parser.add_argument('--ckpt_dir', help='path to checkpoint directory', default=default_ckpt_dir)
    parser.add_argument('--num_batches', help='number of batches (a.k.a. steps or iterations', type=int, default=10)
    parser.add_argument('--batch_size', help='batch size per device (e.g. 32,64)', type=int, default=64)
    args = parser.parse_args()

    num_samples = 64*2*10 # bs * gpus * steps
    height = 224
    width = 224
    num_classes = 1000
 
    if args.model is not None:
        print('Training model: ', args.model)
        if args.model == 'resnet50':
            input_name = tf.keras.applications.ResNet50(weights=None).input_names[0]
            model = tf.keras.applications.ResNet50(weights=None)
        elif args.model == 'inception_v3':
            input_name = tf.keras.applications.inception_v3.InceptionV3(weights=None).input_names[0]
            model = tf.keras.applications.inception_v3.InceptionV3(weights=None)
        elif args.model == 'vgg16':
            input_name = tf.keras.applications.vgg16.VGG16(weights=None).input_names[0]
            model = tf.keras.applications.vgg16.VGG16(weights=None) 
        elif args.model == 'inception_resnet_v2':
            input_name = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(weights=None).input_names[0]
            model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(weights=None)

    subprocess.call('rm -rf %s' % args.ckpt_dir, shell=True)

    filename = glob.glob("/mnt/dataset/imagenet/raw-data/train/n02808440/*.JPEG")
    # if using distribute.Strategy(), only tensorflow native optimizer is allowed currently.
    model.compile(optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.1),
                              loss='categorical_crossentropy',
                              metric='accuracy')
    distribution = tf.contrib.distribute.MirroredStrategy()
    config = tf.estimator.RunConfig(train_distribute=distribution)
    est_inception_v3 = tf.keras.estimator.model_to_estimator(keras_model=model, config=config)
    est_inception_v3.train(input_fn=lambda: imgs_input_fn(filename, None, False, 25, 64), steps=20) 
