#!/usr/bin/env python3
import tensorflow as tf
import numpy as np
import glob
import subprocess
import argparse
import os 
import sys 

def imgs_input_fn(filenames, labels=None, perform_shuffle=False, repeat_count=2, batch_size=64):
    def _parse_function(filename, label):
        image_string = tf.read_file(filename)
        image = tf.image.decode_image(image_string, channels=3)
        image.set_shape([None, None, None])
        image = tf.image.resize_images(image, [224, 224])
        image.set_shape([224, 224, 3])
        image = tf.reverse(image, axis=[2]) # 'RGB'->'BGR'
        d = dict(zip(["input_2"], [image])), label
        return d 
    if labels is None:
        labels = [0]*len(filenames)
    labels=np.array(labels)
    if len(labels.shape) == 1:
        labels = np.expand_dims(labels, axis=1)
    filenames = tf.constant(filenames)
    labels = tf.constant(labels)
    labels = tf.cast(labels, tf.float32)
    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
    dataset = dataset.map(_parse_function)
    if perform_shuffle:
        # Randomizes input using a window of 256 elements (read into memory)
        dataset = dataset.shuffle(buffer_size=256)
    dataset = dataset.repeat(repeat_count)  # Repeats dataset this # times
    dataset = dataset.batch(batch_size)  # Batch size to use
    iterator = dataset.make_one_shot_iterator()
    batch_features, batch_labels = iterator.get_next()
    # if using distribute.Strategy(), must use "return dataset" instead of "return batch_features, batch_lables" 
    return dataset


if __name__ == '__main__':
    default_raw_data_dir = '/mnt/dataset/imagenet/raw-data/train/n02808440/'
    default_ckpt_dir = 'mycheckpoint'
    parser = argparse.ArgumentParser()
    parser.add_argument('--model', help='imagenet model name.', default='resnet50')
    parser.add_argument('--strategy', help='strategy of variable updating', default='mirrored')
    parser.add_argument('--num_gpus', help='number of GPUs used', default=1, type=int)
    parser.add_argument('--raw_data_dir', help='path to directory containing training dataset', default=default_raw_data_dir)
    parser.add_argument('--ckpt_dir', help='path to checkpoint directory', default=default_ckpt_dir)
    parser.add_argument('--num_batches', help='number of batches (a.k.a. steps or iterations', type=int, default=10)
    parser.add_argument('--batch_size', help='batch size per device (e.g. 32,64)', type=int, default=64)
    args = parser.parse_args()

    subprocess.call('rm -r /tmp/tmp*',shell=True) 
 
    if args.model is not None:
        print('Training model: ', args.model)
        if args.model == 'resnet50':
            input_name = tf.keras.applications.ResNet50(weights=None).input_names[0]
            model = tf.keras.applications.ResNet50(weights=None)
        elif args.model == 'inception_v3':
            input_name = tf.keras.applications.inception_v3.InceptionV3(weights=None).input_names[0]
            model = tf.keras.applications.inception_v3.InceptionV3(weights=None)
        elif args.model == 'vgg16':
            input_name = tf.keras.applications.vgg16.VGG16(weights=None).input_names[0]
            model = tf.keras.applications.vgg16.VGG16(weights=None) 
        elif args.model == 'inception_resnet_v2':
            input_name = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(weights=None).input_names[0]
            model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(weights=None)
        elif args.model == 'mobilenet_v2':
            input_name = tf.keras.applications.mobilenet_v2.MobileNetV2(weights=None).input_names[0]
            model = tf.keras.applications.mobilenet_v2.MobileNetV2(weights=None)
        elif args.model == 'densenet':
            input_name = tf.keras.applications.densenet.DenseNet201(weights=None).input_names[0]
            model = tf.keras.applications.densenet.DenseNet201(weights=None)
        elif args.model == 'nasnet':
            input_name = tf.keras.applications.nasnet.NASNetLarge(weights=None).input_names[0]
            model = tf.keras.applications.nasnet.NASNetLarge(weights=None)

    subprocess.call('rm -rf %s' % args.ckpt_dir, shell=True)

    filename = glob.glob(args.raw_data_dir+"*.JPEG")
    # if using distribute.Strategy(), only tensorflow native optimizer is allowed currently.
    model.compile(optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.1),
                              loss='categorical_crossentropy',
                              metric='accuracy')

    if args.strategy == 'mirrored':
        distribution = tf.contrib.distribute.MirroredStrategy()
    elif args.strategy == 'parameter_server':
        distribution = tf.contrib.distribute.ParameterServerStrategy()
    elif args.strategy == 'collective':
        distribution = tf.contrib.distribute.CollectiveAllReduceStrategy(num_gpus_per_worker=1)

    config = tf.estimator.RunConfig( train_distribute = distribution)
    estimator = tf.keras.estimator.model_to_estimator( keras_model = model,
                                                       config = config)
    estimator.train( input_fn = lambda: imgs_input_fn(filename, None, False, 1, args.batch_size),
                     steps = args.num_batches)

    print('S-Bench is done.')

