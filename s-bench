#!/usr/bin/env python3
import tensorflow as tf
import numpy as np
import glob
import subprocess
import argparse
import os 
import sys 
import json
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Dense,Flatten,Dropout
from tensorflow.keras.layers import Conv2D
from tensorflow.keras.layers import MaxPooling2D

def build_alexnet():
    print('Manually building AlexNet...')
    model = Sequential()
    model.add(Conv2D(96,(11,11),strides=(4,4),input_shape=(227,227,3),padding='valid',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
    model.add(Conv2D(256,(5,5),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(384,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(Conv2D(256,(3,3),strides=(1,1),padding='same',activation='relu',kernel_initializer='uniform'))
    model.add(MaxPooling2D(pool_size=(3,3),strides=(2,2)))
    model.add(Flatten())
    model.add(Dense(4096,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(4096,activation='relu'))
    model.add(Dropout(0.5))
    model.add(Dense(1000,activation='softmax'))
    model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])
    print('Model buidling is done.')
    return model

def imgs_input_fn(filenames, labels=None, perform_shuffle=False, repeat_count=2, batch_size=64):
    def _parse_function(filename, label):
        image_string = tf.read_file(filename)
        image = tf.image.decode_image(image_string, channels=3)
        image.set_shape([None, None, None])
        global img_size
        global img_shape
        img_size = list(img_size)
        img_shape = list(img_shape)
        global input_name
        image = tf.image.resize_images(image, img_size)
        image.set_shape(img_shape)
        image = tf.reverse(image, axis=[2]) # 'RGB'->'BGR'
        d = dict(zip([input_name], [image])), label
        return d 
    if labels is None:
        labels = [0]*len(filenames)
    labels=np.array(labels)
    if len(labels.shape) == 1:
        labels = np.expand_dims(labels, axis=1)
    filenames = tf.constant(filenames)
    labels = tf.constant(labels)
    labels = tf.cast(labels, tf.float32)
    dataset = tf.data.Dataset.from_tensor_slices((filenames, labels))
    dataset = dataset.map(_parse_function)
    if perform_shuffle:
        # Randomizes input using a window of 256 elements (read into memory)
        dataset = dataset.shuffle(buffer_size=256)
    dataset = dataset.repeat(repeat_count)  # Repeats dataset this # times
    dataset = dataset.batch(batch_size)  # Batch size to use
    iterator = dataset.make_one_shot_iterator()
    batch_features, batch_labels = iterator.get_next()
    # if using distribute.Strategy(), must use "return dataset" instead of "return batch_features, batch_lables" 
    return dataset


if __name__ == '__main__':
    default_raw_data_dir = '/mnt/dataset/imagenet/raw-data/train/n02808440/'
    default_ckpt_dir = 'mycheckpoint'
    parser = argparse.ArgumentParser()
    parser.add_argument('--model', help='imagenet model name.', default='resnet50')
    parser.add_argument('--strategy', help='strategy of variable updating', default='mirrored')
    parser.add_argument('--num_gpus', help='number of GPUs used', default=1, type=int)
    parser.add_argument('--raw_data_dir', help='path to directory containing training dataset', default=default_raw_data_dir)
    parser.add_argument('--ckpt_dir', help='path to checkpoint directory', default=default_ckpt_dir)
    parser.add_argument('--num_batches', help='number of batches (a.k.a. steps or iterations', type=int, default=10)
    parser.add_argument('--batch_size', help='batch size per device (e.g. 32,64)', type=int, default=64)
    parser.add_argument('--worker', help='e.g. "host1:2222,host2:2222"')
    parser.add_argument('--ps', help='e.g. "host1:2220,host2:2220"')
    parser.add_argument('--task', help='e.g. "worker:0"')
    parser.add_argument('--summary-only', action='store_true')
    args = parser.parse_args()

    subprocess.call('rm -rf /tmp/tmp*',shell=True) 
 
    if args.model is not None:
        print('Training model: ', args.model)
        if args.model == 'resnet50':
            #input_name = tf.keras.applications.ResNet50(weights=None).input_names[0]
            model = tf.keras.applications.ResNet50(weights=None)
        elif args.model == 'alexnet':
            #input_name = build_alexnet().input_names[0]
            model = build_alexnet() 
        elif args.model == 'inception_v3':
            #input_name = tf.keras.applications.inception_v3.InceptionV3(weights=None).input_names[0]
            model = tf.keras.applications.inception_v3.InceptionV3(weights=None)
            input_name = model.input_names[0]
            shape = model.layers[0].output_shape
        elif args.model == 'vgg16':
            #input_name = tf.keras.applications.vgg16.VGG16(weights=None).input_names[0]
            model = tf.keras.applications.vgg16.VGG16(weights=None) 
        elif args.model == 'inception_resnet_v2':
            #input_name = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(weights=None).input_names[0]
            model = tf.keras.applications.inception_resnet_v2.InceptionResNetV2(weights=None)
            input_name = model.input_names[0]
            shape = model.layers[0].output_shape
        elif args.model == 'mobilenet_v2':
            #input_name = tf.keras.applications.mobilenet_v2.MobileNetV2(weights=None).input_names[0]
            model = tf.keras.applications.mobilenet_v2.MobileNetV2(weights=None)
            input_name = model.input_names[0]
            shape = model.layers[0].output_shape
        elif args.model == 'densenet':
            #input_name = tf.keras.applications.densenet.DenseNet201(weights=None).input_names[0]
            model = tf.keras.applications.densenet.DenseNet201(weights=None)
            input_name = model.input_names[0]
            shape = model.layers[0].output_shape
        elif args.model == 'nasnet':
            #input_name = tf.keras.applications.nasnet.NASNetLarge(weights=None).input_names[0]
            model = tf.keras.applications.nasnet.NASNetLarge(weights=None)
            input_name = model.input_names[0]
            shape = model.layers[0].output_shape

    if args.summary_only:
        print(model.summary())
        sys.exit(0)
  
    subprocess.call('rm -rf %s' % args.ckpt_dir, shell=True)

    global input_name
    global img_shape
    global img_size
    input_name = model.input_names[0]
    shape = list(model.layers[0].output_shape)
    shape.pop(0)
    img_shape = tuple(shape)
    shape.pop(-1)
    img_size = tuple(shape)

    filename = glob.glob(args.raw_data_dir+"*.JPEG")
    # if using distribute.Strategy(), only tensorflow native optimizer is allowed currently.
    model.compile(optimizer=tf.train.GradientDescentOptimizer(learning_rate=0.1),
                              loss='categorical_crossentropy',
                              metric='accuracy')

    if args.strategy == 'mirrored':
        distribution = tf.contrib.distribute.MirroredStrategy()
    elif args.strategy == 'parameter_server':
        distribution = tf.contrib.distribute.ParameterServerStrategy()
    elif args.strategy == 'collective':
        distribution = tf.contrib.distribute.CollectiveAllReduceStrategy(num_gpus_per_worker=2)

    config = tf.estimator.RunConfig( train_distribute = distribution)
    est = tf.keras.estimator.model_to_estimator( keras_model = model,
                                                       config = config)

    if args.strategy != 'mirrored':
        tf_config = { "cluster": { "worker": args.worker.split(',') }, "task": {"type": args.task.split(':')[0], "index": args.task.split(':')[1]}}
        if args.ps != None:
            tf_config['cluster']['ps'] = args.ps.split(',')
        print(json.dumps(tf_config))
        os.environ['TF_CONFIG'] = json.dumps(tf_config)
        train_spec = tf.estimator.TrainSpec(input_fn=lambda: imgs_input_fn(filename, None, False, 1, args.batch_size), max_steps = args.num_batches)
        eval_spec = tf.estimator.EvalSpec(input_fn=lambda: imgs_input_fn(filename, None, False, 1, batch_size = 1), steps = 1)
        tf.estimator.train_and_evaluate(est, train_spec, eval_spec)
    else:
        est.train( input_fn = lambda: imgs_input_fn(filename, None, False, 1, args.batch_size), steps = args.num_batches)

    print('S-Bench is done.')

